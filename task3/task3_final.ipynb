{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Task 3 (N-Grams)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kK-TvyrFHElG"
   },
   "outputs": [],
   "source": [
    "# ### For Colab Only ###\n",
    "# !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "# !wget -q https://downloads.apache.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
    "# !tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
    "# !pip install -q findspark\n",
    "\n",
    "# import os\n",
    "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "# os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### For Colab Only ###\n",
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "# from google.colab import auth\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# auth.authenticate_user()\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.credentials = GoogleCredentials.get_application_default()\n",
    "# drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### For Colab Only ###\n",
    "# trainFile = drive.CreateFile({'id':\"1axe3asDoDNJGQlv-iA9wp9laPtybEGzX\"})\n",
    "# trainFile.GetContentFile('train.csv')\n",
    "# testFile = drive.CreateFile({'id':\"1521WHxxG3SJHiPNknvuMcjepyoVY4X39\"})\n",
    "# testFile.GetContentFile('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/cse587/spark-2.4.0-bin-hadoop2.7') ## SPARK Initialization IN VM\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "from pyspark.sql import *\n",
    "spark = SparkSession.builder.appName(\"Genre Prediction\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "data = pd.read_csv(\"train.csv\") \n",
    "# data.head()\n",
    "test = pd.read_csv(\"test.csv\") \n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a5z7-F26HY9p"
   },
   "outputs": [],
   "source": [
    "sqlCtx = SQLContext(sc)\n",
    "df = spark.createDataFrame(data)\n",
    "test_df = spark.createDataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: long (nullable = true)\n",
      " |-- movie_name: string (nullable = true)\n",
      " |-- plot: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      "\n",
      "+--------+----------+--------------------+--------------------+\n",
      "|movie_id|movie_name|                plot|               genre|\n",
      "+--------+----------+--------------------+--------------------+\n",
      "|23890098|Taxi Blues|Shlykov, a hard-w...|['World cinema', ...|\n",
      "+--------+----------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.show(1)\n",
    "# df.show(1, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import *\n",
    "from ast import literal_eval\n",
    "import json\n",
    "\n",
    "# UDF to parse array stored as string using JSON\n",
    "def parse_array_from_string(x):\n",
    "    l = []\n",
    "    x = x.replace('[', '') \n",
    "    x = x.replace(']', '') \n",
    "    x = x.replace(\"'\", '') \n",
    "    res = x.split(',')\n",
    "    for word in res:\n",
    "        l.append(word.strip())\n",
    "    return l\n",
    "\n",
    "retrieve_array = udf(parse_array_from_string, ArrayType(StringType()))\n",
    "\n",
    "def lower_case(x):\n",
    "    res = []\n",
    "    for x_ in x:\n",
    "        res.append(x_.lower())\n",
    "    return res\n",
    "\n",
    "convert_to_lower = udf(lower_case, ArrayType(StringType()))\n",
    "\n",
    "df = df.withColumn(\"label\", convert_to_lower(retrieve_array(col(\"genre\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: long (nullable = true)\n",
      " |-- movie_name: string (nullable = true)\n",
      " |-- plot: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- movie_id: long (nullable = true)\n",
      " |-- movie_name: string (nullable = true)\n",
      " |-- plot: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- label: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "+--------+----------+--------------------+--------------------+--------------------+\n",
      "|movie_id|movie_name|                plot|               genre|               label|\n",
      "+--------+----------+--------------------+--------------------+--------------------+\n",
      "|23890098|Taxi Blues|Shlykov, a hard-w...|['World cinema', ...|[world cinema, dr...|\n",
      "+--------+----------+--------------------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.printSchema()\n",
    "df.printSchema()\n",
    "df.show(1)\n",
    "# df.show(1, truncate= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "#df1 = df\n",
    "#word1 = 'work'\n",
    "def makingLabelsForLabelx(val):\n",
    "    for word in val:\n",
    "        if word1 == word:\n",
    "            return 1\n",
    "    return 0\n",
    "genres = ['drama','comedy','romance film','thriller','action','world cinema','crime fiction','horror','black-and-white','indie','action/adventure',\n",
    "'adventure','family film','short film','romantic drama','animation','musical','science fiction','mystery','romantic comedy']\n",
    "\n",
    "for word in genres:\n",
    "    word1 = word\n",
    "    labeling = udf(makingLabelsForLabelx, IntegerType())\n",
    "    df = df.withColumn(word, labeling(\"label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+--------------------+--------------------+-----+------+------------+--------+------+------------+-------------+------+---------------+-----+----------------+---------+-----------+----------+--------------+---------+-------+---------------+-------+---------------+\n",
      "|movie_id|movie_name|                plot|               genre|               label|drama|comedy|romance film|thriller|action|world cinema|crime fiction|horror|black-and-white|indie|action/adventure|adventure|family film|short film|romantic drama|animation|musical|science fiction|mystery|romantic comedy|\n",
      "+--------+----------+--------------------+--------------------+--------------------+-----+------+------------+--------+------+------------+-------------+------+---------------+-----+----------------+---------+-----------+----------+--------------+---------+-------+---------------+-------+---------------+\n",
      "|23890098|Taxi Blues|Shlykov, a hard-w...|['World cinema', ...|[world cinema, dr...|    1|     0|           0|       0|     0|           1|            0|     0|              0|    0|               0|        0|          0|         0|             0|        0|      0|              0|      0|              0|\n",
      "+--------+----------+--------------------+--------------------+--------------------+-----+------+------------+--------+------+------------+-------------+------+---------------+-----+----------------+---------+-----------+----------+--------------+---------+-------+---------------+-------+---------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qctcmPcwHZLE"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.sql.functions import lower, col\n",
    "\n",
    "# Clean text\n",
    "df = df.withColumn(\"text\", regexp_replace(\"plot\", \"[^a-zA-Z\\\\s]\", \"\"))\n",
    "test_df = test_df.withColumn(\"text\", regexp_replace(\"plot\", \"[^a-zA-Z\\\\s]\", \"\"))\n",
    "\n",
    "# Tokenize text\n",
    "tokenizer = Tokenizer(inputCol='text', outputCol='words_token')\n",
    "df = tokenizer.transform(df)\n",
    "test_df = tokenizer.transform(test_df)\n",
    "\n",
    "\n",
    "# Remove stop words\n",
    "remover = StopWordsRemover(inputCol='words_token', outputCol='words_clean')\n",
    "df = remover.transform(df)\n",
    "test_df = remover.transform(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PRw-JMulpQ-7"
   },
   "outputs": [],
   "source": [
    "# Applying Ngrams on the clean words \n",
    "from pyspark.ml.feature import NGram\n",
    "ngram = NGram(inputCol=\"words_clean\", outputCol=\"ngrams\")\n",
    "ngramDataFrame = ngram.transform(df)\n",
    "test_df = ngram.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "VNOWyV2YH1O8",
    "outputId": "e0662aff-3677-4b2e-e14c-6fc773a763c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count-vectorizer-model Exist\n",
      "Transforming data\n",
      "Transforming data Done\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "model_path1 = \"models/count-vectorizer-model\"\n",
    "file1 = pathlib.Path(model_path1)\n",
    "from pyspark.ml.feature import CountVectorizer,CountVectorizerModel\n",
    "if file1.exists():\n",
    "    print(\"count-vectorizer-model Exist\")\n",
    "    model = CountVectorizerModel.load(model_path1)\n",
    "else:\n",
    "    print(\"count-vectorizer-model Doesnot Exist...Training Model\")\n",
    "    cv = CountVectorizer(inputCol=\"ngrams\", outputCol=\"features\",vocabSize=10000)\n",
    "    model = cv.fit(ngramDataFrame)\n",
    "    print(\"Saving Trained Model\")\n",
    "    model.save(model_path1)\n",
    "\n",
    "print(\"Transforming data\")\n",
    "wRescaledData = model.transform(ngramDataFrame)\n",
    "test_wRescaledData = model.transform(test_df)\n",
    "print(\"Transforming data Done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtrainDF1 = wRescaledData.select(col(\"drama\").alias(\"label\"), \"features\")\n",
    "wtrainDF2 = wRescaledData.select(col(\"comedy\").alias(\"label\"), \"features\")\n",
    "wtrainDF3 = wRescaledData.select(col(\"romance film\").alias(\"label\"), \"features\")\n",
    "wtrainDF4 = wRescaledData.select(col(\"thriller\").alias(\"label\"), \"features\")\n",
    "wtrainDF5 = wRescaledData.select(col(\"action\").alias(\"label\"), \"features\")\n",
    "wtrainDF6 = wRescaledData.select(col(\"world cinema\").alias(\"label\"), \"features\")\n",
    "wtrainDF7 = wRescaledData.select(col(\"crime fiction\").alias(\"label\"), \"features\")\n",
    "wtrainDF8 = wRescaledData.select(col(\"horror\").alias(\"label\"), \"features\")\n",
    "wtrainDF9 = wRescaledData.select(col(\"black-and-white\").alias(\"label\"), \"features\")\n",
    "wtrainDF10 = wRescaledData.select(col(\"indie\").alias(\"label\"), \"features\")\n",
    "wtrainDF11 = wRescaledData.select(col(\"action/adventure\").alias(\"label\"), \"features\")\n",
    "wtrainDF12 = wRescaledData.select(col(\"adventure\").alias(\"label\"), \"features\")\n",
    "wtrainDF13 = wRescaledData.select(col(\"family film\").alias(\"label\"), \"features\")\n",
    "wtrainDF14 = wRescaledData.select(col(\"short film\").alias(\"label\"), \"features\")\n",
    "wtrainDF15 = wRescaledData.select(col(\"romantic drama\").alias(\"label\"), \"features\")\n",
    "wtrainDF16 = wRescaledData.select(col(\"animation\").alias(\"label\"), \"features\")\n",
    "wtrainDF17 = wRescaledData.select(col(\"musical\").alias(\"label\"), \"features\")\n",
    "wtrainDF18 = wRescaledData.select(col(\"science fiction\").alias(\"label\"), \"features\")\n",
    "wtrainDF19 = wRescaledData.select(col(\"mystery\").alias(\"label\"), \"features\")\n",
    "wtrainDF20 = wRescaledData.select(col(\"romantic comedy\").alias(\"label\"), \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtestDF = test_wRescaledData.select(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vM3Kz3p5H1YJ"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression,LogisticRegressionModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "lrm = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ETfG9izOH1fC",
    "outputId": "1fd37ff3-21cb-418f-82dd-cda4dabcf68b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR-model Exist\n"
     ]
    }
   ],
   "source": [
    "model_path3 = \"models/lr-model1\"\n",
    "file3 = pathlib.Path(model_path3)\n",
    "if file3.exists():\n",
    "    print(\"LR-model Exist\")\n",
    "    wmodel1 = LogisticRegressionModel.load(model_path3)\n",
    "else:\n",
    "    print(\"LR-model Doesnot Exist...Training Model\")\n",
    "    wmodel1 = lrm.fit(wtrainDF1)\n",
    "    print(\"Saving Trained Model\")\n",
    "    wmodel1.save(model_path3)\n",
    "    \n",
    "wresult1 = wmodel1.transform(wtestDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TBI0lgh0IKGr",
    "outputId": "1e10049c-3588-4958-c0ec-8b05f871a86b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR-model Exist\n"
     ]
    }
   ],
   "source": [
    "model_path4 = \"models/lr-model2\"\n",
    "file4 = pathlib.Path(model_path4)\n",
    "if file4.exists():\n",
    "    print(\"LR-model Exist\")\n",
    "    wmodel2 = LogisticRegressionModel.load(model_path4)\n",
    "else:\n",
    "    print(\"LR-model Doesnot Exist...Training Model\")\n",
    "    wmodel2 = lrm.fit(wtrainDF2)\n",
    "    print(\"Saving Trained Model\")\n",
    "    wmodel2.save(model_path4)\n",
    "    \n",
    "wresult2 = wmodel2.transform(wtestDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nzB8v2S7INRd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR-model Exist\n"
     ]
    }
   ],
   "source": [
    "model_path5 = \"models/lr-model3\"\n",
    "file5 = pathlib.Path(model_path5)\n",
    "if file5.exists():\n",
    "    print(\"LR-model Exist\")\n",
    "    wmodel3 = LogisticRegressionModel.load(model_path5)\n",
    "else:\n",
    "    print(\"LR-model Doesnot Exist...Training Model\")\n",
    "    wmodel3 = lrm.fit(wtrainDF3)\n",
    "    print(\"Saving Trained Model\")\n",
    "    wmodel3.save(model_path5)\n",
    "    \n",
    "wresult3 = wmodel3.transform(wtestDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "njf_F4FlIP9C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR-model Exist\n"
     ]
    }
   ],
   "source": [
    "model_path6 = \"models/lr-model4\"\n",
    "file6 = pathlib.Path(model_path6)\n",
    "if file6.exists():\n",
    "    print(\"LR-model Exist\")\n",
    "    wmodel4 = LogisticRegressionModel.load(model_path6)\n",
    "else:\n",
    "    print(\"LR-model Doesnot Exist...Training Model\")\n",
    "    wmodel4 = lrm.fit(wtrainDF4)\n",
    "    print(\"Saving Trained Model\")\n",
    "    wmodel4.save(model_path6)\n",
    "    \n",
    "wresult4 = wmodel4.transform(wtestDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HcKTN1orIQDy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR-model Exist\n"
     ]
    }
   ],
   "source": [
    "model_path7 = \"models/lr-model5\"\n",
    "file7 = pathlib.Path(model_path7)\n",
    "if file7.exists():\n",
    "    print(\"LR-model Exist\")\n",
    "    wmodel5 = LogisticRegressionModel.load(model_path7)\n",
    "else:\n",
    "    print(\"LR-model Doesnot Exist...Training Model\")\n",
    "    wmodel5 = lrm.fit(wtrainDF5)\n",
    "    print(\"Saving Trained Model\")\n",
    "    wmodel5.save(model_path7)\n",
    "    \n",
    "wresult5 = wmodel5.transform(wtestDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TLddXcBTIQGc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR-model Exist\n"
     ]
    }
   ],
   "source": [
    "model_path8 = \"models/lr-model6\"\n",
    "file8 = pathlib.Path(model_path8)\n",
    "if file8.exists():\n",
    "    print(\"LR-model Exist\")\n",
    "    wmodel6 = LogisticRegressionModel.load(model_path8)\n",
    "else:\n",
    "    print(\"LR-model Doesnot Exist...Training Model\")\n",
    "    wmodel6 = lrm.fit(wtrainDF6)\n",
    "    print(\"Saving Trained Model\")\n",
    "    wmodel6.save(model_path8)\n",
    "    \n",
    "wresult6 = wmodel6.transform(wtestDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pAOQ4-mcIQI_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR-model Exist\n"
     ]
    }
   ],
   "source": [
    "model_path9 = \"models/lr-model7\"\n",
    "file9 = pathlib.Path(model_path9)\n",
    "if file9.exists():\n",
    "    print(\"LR-model Exist\")\n",
    "    wmodel7 = LogisticRegressionModel.load(model_path9)\n",
    "else:\n",
    "    print(\"LR-model Doesnot Exist...Training Model\")\n",
    "    wmodel7 = lrm.fit(wtrainDF7)\n",
    "    print(\"Saving Trained Model\")\n",
    "    wmodel7.save(model_path9)\n",
    "    \n",
    "wresult7 = wmodel7.transform(wtestDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zyEBAj9KIQLM"
   },
   "outputs": [],
   "source": [
    "model_path10 = \"models/lr-model8\"\n",
    "file10 = pathlib.Path(model_path10)\n",
    "if file10.exists():\n",
    "    wmodel8 = LogisticRegressionModel.load(model_path10)\n",
    "else:\n",
    "    wmodel8 = lrm.fit(wtrainDF8)\n",
    "    wmodel8.save(model_path10)\n",
    "wresult8 = wmodel8.transform(wtestDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k1FGgcytIQN7"
   },
   "outputs": [],
   "source": [
    "model_path11 = \"models/lr-model9\"\n",
    "file11 = pathlib.Path(model_path11)\n",
    "if file11.exists():\n",
    "    wmodel9 = LogisticRegressionModel.load(model_path11)\n",
    "else:\n",
    "    wmodel9 = lrm.fit(wtrainDF9)\n",
    "    wmodel9.save(model_path11)\n",
    "wresult9 = wmodel9.transform(wtestDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xiot_vaDIQQJ"
   },
   "outputs": [],
   "source": [
    "model_path12 = \"models/lr-model10\"\n",
    "file12 = pathlib.Path(model_path12)\n",
    "if file12.exists():\n",
    "    wmodel10 = LogisticRegressionModel.load(model_path12)\n",
    "else:\n",
    "    wmodel10 = lrm.fit(wtrainDF10)\n",
    "    wmodel10.save(model_path12)\n",
    "wresult10 = wmodel10.transform(wtestDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g8ht__hrIQSX"
   },
   "outputs": [],
   "source": [
    "model_path13 = \"models/lr-model11\"\n",
    "file13 = pathlib.Path(model_path13)\n",
    "if file13.exists():\n",
    "    wmodel11 = LogisticRegressionModel.load(model_path13)\n",
    "else:\n",
    "    wmodel11 = lrm.fit(wtrainDF11)\n",
    "    wmodel11.save(model_path13)\n",
    "wresult11 = wmodel11.transform(wtestDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VwFgsZC1Ivo7"
   },
   "outputs": [],
   "source": [
    "model_path14 = \"models/lr-model12\"\n",
    "file14 = pathlib.Path(model_path14)\n",
    "if file14.exists():\n",
    "    wmodel12 = LogisticRegressionModel.load(model_path14)\n",
    "else:\n",
    "    wmodel12 = lrm.fit(wtrainDF12)\n",
    "    wmodel12.save(model_path14)\n",
    "wresult12 = wmodel12.transform(wtestDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uY9xv-2kIvrO"
   },
   "outputs": [],
   "source": [
    "model_path15 = \"models/lr-model13\"\n",
    "file15 = pathlib.Path(model_path15)\n",
    "if file15.exists():\n",
    "    wmodel13 = LogisticRegressionModel.load(model_path15)\n",
    "else:\n",
    "    wmodel13 = lrm.fit(wtrainDF13)\n",
    "    wmodel13.save(model_path15)\n",
    "wresult13 = wmodel13.transform(wtestDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ncxNBjBIvtn"
   },
   "outputs": [],
   "source": [
    "model_path16 = \"models/lr-model14\"\n",
    "file16 = pathlib.Path(model_path16)\n",
    "if file16.exists():\n",
    "    wmodel14 = LogisticRegressionModel.load(model_path16)\n",
    "else:\n",
    "    wmodel14 = lrm.fit(wtrainDF14)\n",
    "    wmodel14.save(model_path16)\n",
    "wresult14 = wmodel14.transform(wtestDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EfOELV89IvwK"
   },
   "outputs": [],
   "source": [
    "model_path17 = \"models/lr-model15\"\n",
    "file17 = pathlib.Path(model_path17)\n",
    "if file17.exists():\n",
    "    wmodel15 = LogisticRegressionModel.load(model_path17)\n",
    "else:\n",
    "    wmodel15 = lrm.fit(wtrainDF15)\n",
    "    wmodel15.save(model_path17)\n",
    "wresult15 = wmodel15.transform(wtestDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "24BbIgqlIvy3"
   },
   "outputs": [],
   "source": [
    "model_path18 = \"models/lr-model16\"\n",
    "file18 = pathlib.Path(model_path18)\n",
    "if file18.exists():\n",
    "    wmodel16 = LogisticRegressionModel.load(model_path18)\n",
    "else:\n",
    "    wmodel16 = lrm.fit(wtrainDF16)\n",
    "    wmodel16.save(model_path18)\n",
    "wresult16 = wmodel16.transform(wtestDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "56ggG4dDIv0Z"
   },
   "outputs": [],
   "source": [
    "model_path19 = \"models/lr-model17\"\n",
    "file19 = pathlib.Path(model_path19)\n",
    "if file19.exists():\n",
    "    wmodel17 = LogisticRegressionModel.load(model_path19)\n",
    "else:\n",
    "    wmodel17 = lrm.fit(wtrainDF17)\n",
    "    wmodel17.save(model_path19)\n",
    "wresult17 = wmodel17.transform(wtestDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Ulhd7G2Iv2h"
   },
   "outputs": [],
   "source": [
    "model_path20 = \"models/lr-model18\"\n",
    "file20 = pathlib.Path(model_path20)\n",
    "if file20.exists():\n",
    "    wmodel18 = LogisticRegressionModel.load(model_path20)\n",
    "else:\n",
    "    wmodel18 = lrm.fit(wtrainDF18)\n",
    "    wmodel18.save(model_path20)\n",
    "wresult18 = wmodel18.transform(wtestDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9fyB2tWjIv45"
   },
   "outputs": [],
   "source": [
    "model_path21 = \"models/lr-model19\"\n",
    "file21 = pathlib.Path(model_path21)\n",
    "if file21.exists():\n",
    "    wmodel19 = LogisticRegressionModel.load(model_path21)\n",
    "else:\n",
    "    wmodel19 = lrm.fit(wtrainDF19)\n",
    "    wmodel19.save(model_path21)\n",
    "wresult19 = wmodel19.transform(wtestDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qt7CTMgUI9jY"
   },
   "outputs": [],
   "source": [
    "model_path22 = \"models/lr-model20\"\n",
    "file22 = pathlib.Path(model_path22)\n",
    "if file22.exists():\n",
    "    wmodel20 = LogisticRegressionModel.load(model_path22)\n",
    "else:\n",
    "    wmodel20 = lrm.fit(wtrainDF20)\n",
    "    wmodel20.save(model_path22)\n",
    "wresult20 = wmodel20.transform(wtestDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "26ZeS7M4I9oA",
    "outputId": "e050298f-ce35-4267-b5ee-cd72047bc48c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction1: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wresult1 = wresult1.withColumnRenamed(\"prediction\",\"prediction1\")\n",
    "wresult1.printSchema()\n",
    "wresult2 = wresult2.withColumnRenamed(\"prediction\",\"prediction2\")\n",
    "wresult3 = wresult3.withColumnRenamed(\"prediction\",\"prediction3\")\n",
    "wresult4 = wresult4.withColumnRenamed(\"prediction\",\"prediction4\")\n",
    "wresult5 = wresult5.withColumnRenamed(\"prediction\",\"prediction5\")\n",
    "wresult6 = wresult6.withColumnRenamed(\"prediction\",\"prediction6\")\n",
    "wresult7 = wresult7.withColumnRenamed(\"prediction\",\"prediction7\")\n",
    "wresult8 = wresult8.withColumnRenamed(\"prediction\",\"prediction8\")\n",
    "wresult9 = wresult9.withColumnRenamed(\"prediction\",\"prediction9\")\n",
    "wresult10 = wresult10.withColumnRenamed(\"prediction\",\"prediction10\")\n",
    "wresult11 = wresult11.withColumnRenamed(\"prediction\",\"prediction11\")\n",
    "wresult12 = wresult12.withColumnRenamed(\"prediction\",\"prediction12\")\n",
    "wresult13 = wresult13.withColumnRenamed(\"prediction\",\"prediction13\")\n",
    "wresult14 = wresult14.withColumnRenamed(\"prediction\",\"prediction14\")\n",
    "wresult15 = wresult15.withColumnRenamed(\"prediction\",\"prediction15\")\n",
    "wresult16 = wresult16.withColumnRenamed(\"prediction\",\"prediction16\")\n",
    "wresult17 = wresult17.withColumnRenamed(\"prediction\",\"prediction17\")\n",
    "wresult18 = wresult18.withColumnRenamed(\"prediction\",\"prediction18\")\n",
    "wresult19 = wresult19.withColumnRenamed(\"prediction\",\"prediction19\")\n",
    "wresult20 = wresult20.withColumnRenamed(\"prediction\",\"prediction20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tNt13P-vI9qc"
   },
   "outputs": [],
   "source": [
    "w = wresult1.join(wresult2,on = ['features'],how = 'inner').select(\"features\",\"prediction1\",\"prediction2\")\n",
    "w = w.dropDuplicates(['features'])\n",
    "\n",
    "w = w.join(wresult3,on = ['features'],how = 'inner').select(\"features\",\"prediction1\",\"prediction2\",\"prediction3\")\n",
    "w = w.dropDuplicates(['features'])\n",
    "\n",
    "w = w.join(wresult4,on = ['features'],how = 'inner').select(\"features\",\"prediction1\",\"prediction2\",\"prediction3\",\"prediction4\")\n",
    "w = w.dropDuplicates(['features'])\n",
    "\n",
    "w = w.join(wresult5,on = ['features'],how = 'inner').select(\"features\",\"prediction1\",\"prediction2\",\"prediction3\",\"prediction4\",\"prediction5\")\n",
    "w = w.dropDuplicates(['features'])\n",
    "\n",
    "w = w.join(wresult6,on = ['features'],how = 'inner').select(\"features\",\"prediction1\",\"prediction2\",\"prediction3\",\"prediction4\",\"prediction5\",\"prediction6\")\n",
    "w = w.dropDuplicates(['features'])\n",
    "\n",
    "w = w.join(wresult7,on = ['features'],how = 'inner').select(\"features\",\"prediction1\",\"prediction2\",\"prediction3\",\"prediction4\",\"prediction5\",\"prediction6\",\"prediction7\")\n",
    "w = w.dropDuplicates(['features'])\n",
    "\n",
    "w = w.join(wresult8,on = ['features'],how = 'inner').select(\"features\",\"prediction1\",\"prediction2\",\"prediction3\",\"prediction4\",\"prediction5\",\"prediction6\",\"prediction7\",\"prediction8\")\n",
    "w = w.dropDuplicates(['features'])\n",
    "\n",
    "w = w.join(wresult9,on = ['features'],how = 'inner').select(\"features\",\"prediction1\",\"prediction2\",\"prediction3\",\"prediction4\",\"prediction5\",\"prediction6\",\"prediction7\",\"prediction8\",\"prediction9\")\n",
    "w = w.dropDuplicates(['features'])\n",
    "\n",
    "w = w.join(wresult10,on = ['features'],how = 'inner')\n",
    "w = w.dropDuplicates(['features'])\n",
    "\n",
    "w = w.join(wresult11,on = ['features'],how = 'inner')\n",
    "w = w.dropDuplicates(['features'])\n",
    "\n",
    "w = w.join(wresult12,on = ['features'],how = 'inner')\n",
    "w = w.dropDuplicates(['features'])\n",
    "\n",
    "w = w.join(wresult13,on = ['features'],how = 'inner')\n",
    "w = w.dropDuplicates(['features'])\n",
    "\n",
    "w = w.join(wresult14,on = ['features'],how = 'inner')\n",
    "w = w.dropDuplicates(['features'])\n",
    "\n",
    "w = w.join(wresult15,on = ['features'],how = 'inner')\n",
    "w = w.dropDuplicates(['features'])\n",
    "\n",
    "w = w.join(wresult16,on = ['features'],how = 'inner')\n",
    "w = w.dropDuplicates(['features'])\n",
    "\n",
    "w = w.join(wresult17,on = ['features'],how = 'inner')\n",
    "w = w.dropDuplicates(['features'])\n",
    "\n",
    "w = w.join(wresult18,on = ['features'],how = 'inner')\n",
    "w = w.dropDuplicates(['features'])\n",
    "\n",
    "w = w.join(wresult19,on = ['features'],how = 'inner')\n",
    "w = w.dropDuplicates(['features'])\n",
    "\n",
    "w = w.join(wresult20,on = ['features'],how = 'inner').select(\"features\",\"prediction1\",\"prediction2\",\"prediction3\",\"prediction4\",\"prediction5\",\"prediction6\",\"prediction7\",\"prediction8\",\"prediction9\",\"prediction10\",\"prediction11\",\"prediction12\",\"prediction13\",\"prediction14\",\"prediction15\",\"prediction16\",\"prediction17\",\"prediction18\",\"prediction19\",\"prediction20\")\n",
    "w = w.dropDuplicates(['features'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "IaG7aISmJHXk",
    "outputId": "dec9d2ed-4e30-4b0a-eacf-b510bcefd3b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: long (nullable = true)\n",
      " |-- movie_name: string (nullable = true)\n",
      " |-- plot: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- words_token: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- words_clean: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngrams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_wRescaledData.printSchema()\n",
    "test_wRescaledData_final = test_wRescaledData.select(\"movie_id\",\"features\")\n",
    "w = w.join(test_wRescaledData_final,on = ['features'],how = 'inner')\n",
    "w = w.dropDuplicates(['movie_id'])\n",
    "#w.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mtZeqy_yJRp0"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "import math\n",
    "#df1 = df\n",
    "#word1 = 'work'\n",
    "def makingLabelsForLabelx(val1,val2,val3,val4,val5,val6,val7,val8,val9,val10,val11,val12,val13,val14,val15,val16,val17,val18,val19,val20):\n",
    "    val1 = str(math.floor(val1))\n",
    "    val2 = str(math.floor(val2))\n",
    "    val3 = str(math.floor(val3))\n",
    "    val4 = str(math.floor(val4))\n",
    "    val5 = str(math.floor(val5))\n",
    "    val6 = str(math.floor(val6))\n",
    "    val7 = str(math.floor(val7))\n",
    "    val8 = str(math.floor(val8))\n",
    "    val9 = str(math.floor(val9))\n",
    "    val10 = str(math.floor(val10))\n",
    "    val11 = str(math.floor(val11))\n",
    "    val12 = str(math.floor(val12))\n",
    "    val13 = str(math.floor(val13))\n",
    "    val14 = str(math.floor(val14))\n",
    "    val15 = str(math.floor(val15))\n",
    "    val16 = str(math.floor(val16))\n",
    "    val17 = str(math.floor(val17))\n",
    "    val18 = str(math.floor(val18))\n",
    "    val19 = str(math.floor(val19))\n",
    "    val20 = str(math.floor(val20))\n",
    "    return val1+\" \"+ val2+ \" \"+val3+ \" \"+ val4+ \" \"+ val5+ \" \"+ val6+ \" \"+ val7+ \" \"+val8 + \" \"+ val9+ \" \"+ val10+ \" \"+ val11+ \" \"+ val12+ \" \"+ val13+ \" \"+ val14+ \" \"+ val15+ \" \"+ val16+ \" \"+ val17+ \" \"+ val18+ \" \"+ val19+ \" \"+ val20\n",
    "\n",
    "wlabeling = udf(makingLabelsForLabelx, StringType())\n",
    "wdf_pred = w.withColumn(\"predictions\", wlabeling(\"prediction1\",\"prediction2\",\"prediction3\",\"prediction4\",\"prediction5\",\"prediction6\",\"prediction7\",\"prediction8\",\"prediction9\",\"prediction10\",\"prediction11\",\"prediction12\",\"prediction13\",\"prediction14\",\"prediction15\",\"prediction16\",\"prediction17\",\"prediction18\",\"prediction19\",\"prediction20\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jG-xuHQaJT5x"
   },
   "outputs": [],
   "source": [
    "wdf_final = wdf_pred.select(\"movie_id\",\"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|movie_id|         predictions|\n",
      "+--------+--------------------+\n",
      "|15739815|1 1 0 0 0 0 0 0 0...|\n",
      "|11272068|0 0 0 1 1 0 0 0 0...|\n",
      "|20312589|1 0 1 0 0 1 1 0 1...|\n",
      "| 4635580|1 0 0 0 0 0 0 0 0...|\n",
      "|23658166|1 1 0 0 0 0 0 0 1...|\n",
      "| 1428872|0 1 0 0 1 0 0 0 0...|\n",
      "|   62693|1 0 0 1 1 0 0 0 1...|\n",
      "|19286389|1 0 1 0 0 0 0 0 0...|\n",
      "| 7003785|0 1 0 0 1 0 1 0 0...|\n",
      "| 5565692|0 1 1 0 0 1 0 0 1...|\n",
      "|33916241|0 1 0 0 0 0 0 0 0...|\n",
      "| 1356971|1 1 1 1 0 0 0 0 0...|\n",
      "|35968313|1 0 0 0 0 0 0 0 0...|\n",
      "|  296252|0 0 0 1 1 0 0 0 0...|\n",
      "|24817139|0 1 0 1 1 1 0 0 0...|\n",
      "|23863620|1 0 1 0 0 0 1 1 0...|\n",
      "|24003057|0 0 0 0 1 0 0 0 0...|\n",
      "| 2268290|0 0 0 1 1 0 0 1 0...|\n",
      "|13949859|1 0 0 1 0 0 0 0 0...|\n",
      "|24225138|1 1 0 0 0 0 0 0 0...|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wdf_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DCB8ltnjJWTJ"
   },
   "outputs": [],
   "source": [
    "wdf_final.repartition(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").save(\"results_task3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7777"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdf_final.count()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "assignment3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
